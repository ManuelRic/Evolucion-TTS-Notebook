{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "698462d6",
      "metadata": {
        "id": "698462d6"
      },
      "source": [
        "# GRUPO 6: TEXT TO SPEECH"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aeecc545",
      "metadata": {
        "id": "aeecc545"
      },
      "source": [
        "## INTRODUCCIÓN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7a4fe4b",
      "metadata": {
        "id": "c7a4fe4b"
      },
      "source": [
        "Nuestro proyecto trata sobre los sistemas Text To Speech, y nuestra intención es ofrecer una visión clara de cómo ha progresado esta tecnología a lo largo del tiempo, destacando los avances más novedosos relacionados con la síntesis neuronal, los distintos enfoques técnicos que han surgido, y las características que los diferencian entre sí.\n",
        "\n",
        "Esta tecnología es súper importante en muchas áreas: desde ayudantes virtuales como Google Assistant o Siri, hasta programas que leen la pantalla para gente con problemas de visión, sin olvidar los GPS, las voces automatizadas que oímos al llamar a algún sitio, los juegos o la creación de videos y demás contenidos.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1XJfBIiYe5Bjxa4sgE9n-12WIEE5EPM-a\" style=\"width:550px; height:auto;\" />\n",
        "\n",
        "Además, nuestro objetivo no es solo ofreceros una explicación teórica, sino también facilitar una experiencia interactiva. En este cuaderno buscamos proporcionaros una información extra, donde se pueda ver como se maneja código y relacionarlo con ámbitos de la asignatura."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importante: Crea tu propia copia para guardar tus cambios\n",
        "\n",
        "Este cuaderno se abre en **modo playground**, lo que significa que puedes ejecutar y modificar el contenido, pero:\n",
        "\n",
        "- Los cambios que hagas **NO se guardarán en el archivo original**.\n",
        "- Cada vez que abras el notebook desde este enlace, empezarás con la versión original, sin tus modificaciones previas.\n",
        "\n",
        "Para trabajar de forma segura y guardar tu progreso, debes:  \n",
        "**Ir al menú superior y hacer clic en:**  \n",
        "**Archivo > Guardar una copia en Drive**\n",
        "\n",
        "Esto creará **tu propia copia privada** en tu Google Drive donde podrás guardar todos tus cambios.\n"
      ],
      "metadata": {
        "id": "VvwtW4KtNW4A"
      },
      "id": "VvwtW4KtNW4A"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyworld\n",
        "!pip install gTTS\n",
        "!pip install ipywidgets"
      ],
      "metadata": {
        "id": "g8QeoN14PyCO"
      },
      "id": "g8QeoN14PyCO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c9536ca1",
      "metadata": {
        "id": "c9536ca1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pyworld as pw\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "import ipywidgets as widgets\n",
        "from gtts import gTTS\n",
        "from IPython.display import Audio, display\n",
        "import os\n",
        "from scipy import signal"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2de4bd4",
      "metadata": {
        "id": "d2de4bd4"
      },
      "source": [
        "## SÍNTESIS CONCATENATIVA"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04b15d54",
      "metadata": {
        "id": "04b15d54"
      },
      "source": [
        "Aunque hoy en día nos suene normal que una máquina hable con nosotros, conseguirlo no fue nada fácil. La tecnología Text-to-Speech ha pasado por varias etapas hasta sonar tan natural como ahora.\n",
        "\n",
        "Como ya hemos podido ver en la página web los sistemas concatenativos tienen muchas limitaciones pero son fáciles de mantener. A continuación puedes observar la version den python de synth-me en inglés.\n",
        "\n",
        "Si te interesa solo hacerlo en español puedes visitar el apartado de nuestra página web \"Síntesis Concatenativa\" dónde también encontrarás un tutorial para hacerlo con tu propia voz.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51fc2820",
      "metadata": {
        "id": "51fc2820"
      },
      "outputs": [],
      "source": [
        "# 1. Clonar el repositorio\n",
        "!git clone https://github.com/stephengrice/synth-me.git\n",
        "\n",
        "# 2. Ir al directorio principal\n",
        "%cd synth-me\n",
        "\n",
        "# 3. Añadir el subdirectorio al path de Python\n",
        "import sys\n",
        "sys.path.append('./synthme')\n",
        "\n",
        "# 3. Importa la función desde el archivo tts.py\n",
        "from tts import text_to_speech"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a69a3ce",
      "metadata": {
        "id": "5a69a3ce"
      },
      "outputs": [],
      "source": [
        "message = input(\"Message: \")\n",
        "\n",
        "# Ejecuta la síntesis de voz\n",
        "text_to_speech(message, debug=True, use_pronunciation_dict=True)\n",
        "\n",
        "Audio('output.wav')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdfd1d90",
      "metadata": {
        "id": "bdfd1d90"
      },
      "source": [
        "## SÍNTESIS PARAMÉTRICA"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f86e2480",
      "metadata": {
        "id": "f86e2480"
      },
      "source": [
        "Después llegaron los modelos matemáticos. En vez de usar grabaciones completas, estos sistemas tratan de simular la voz con fórmulas y estadísticas.\n",
        "\n",
        "Como ya hemos comprobado en la web, la síntesis paramétrica es muy superior a la concatenativa. Por eso hemos querido que la puedas probar en ambos lugares, pero en este cuaderno queremos introduciros a los vocododres.\n",
        "\n",
        "Este cuaderno te permite experimentar con la síntesis paramétrica utilizando un vocoder basado en el modelo WORLD, muy popular por su calidad y flexibilidad. El proceso que hemos seguido es típico en esta clase de síntesis:\n",
        "\n",
        "1. Extracción de parámetros: A partir de la señal de voz original, se extraen tres componentes principales:\n",
        "\n",
        "  - La frecuencia fundamental (F0), que representa el tono de la voz.\n",
        "\n",
        "  - La envolvente espectral, que define el timbre.\n",
        "\n",
        "  - Las componentes aperiódicas, que reflejan el ruido y las fricativas.\n",
        "\n",
        "2. Síntesis: Estos parámetros se usan para reconstruir una versión de la voz original. Aunque no es una copia exacta, el resultado puede sonar muy natural si los parámetros están bien estimados."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "filename = next(iter(uploaded))\n",
        "\n",
        "print(f\"Archivo cargado: {filename}\")\n",
        "\n",
        "x, fs = librosa.load(filename, sr=16000)\n",
        "x = x.astype(np.float64)\n",
        "\n",
        "print(f\"Audio cargado con fs = {fs}, duración = {len(x)/fs:.2f} segundos\")\n",
        "\n",
        "display(Audio(x, rate=fs))"
      ],
      "metadata": {
        "id": "bUOM9CsQnU4N"
      },
      "id": "bUOM9CsQnU4N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f13c73a",
      "metadata": {
        "id": "8f13c73a"
      },
      "outputs": [],
      "source": [
        "# F0/Pitch\n",
        "_f0, t = pw.harvest(x, fs)\n",
        "\n",
        "# Envolvente espectral\n",
        "sp = pw.cheaptrick(x, _f0, t, fs)\n",
        "\n",
        "# Componentes aperiódicas\n",
        "ap = pw.d4c(x, _f0, t, fs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "810f01d1",
      "metadata": {
        "id": "810f01d1"
      },
      "outputs": [],
      "source": [
        "# Síntesis a partir de los parámetros\n",
        "y = pw.synthesize(_f0, sp, ap, fs)\n",
        "\n",
        "display(Audio(y, rate=fs))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Además, hemos añadido una herramienta interactiva que te permite modificar la F0 (frecuencia fundamental) de forma dinámica. Esto se traduce en un cambio de tono, es decir, puedes hacer que la voz suene más grave o más aguda. A medida que mueves el deslizador:\n",
        "\n",
        "- Se actualiza la curva de F0 en el gráfico superior.\n",
        "\n",
        "- Se genera una nueva señal con el tono modificado.\n",
        "\n",
        "- Se actualiza el espectrograma para que puedas visualizar cómo cambia el contenido frecuencial de la señal.\n",
        "\n",
        "Te animamos a experimentar con diferentes valores de pitch y observar cómo cambia la señal sintetizada.<"
      ],
      "metadata": {
        "id": "P9bdlKTvjlS-"
      },
      "id": "P9bdlKTvjlS-"
    },
    {
      "cell_type": "code",
      "source": [
        "def generar_espectrograma(audio, fs, title='Espectrograma', cmap='magma', y_axis='mel', figsize=(10, 4)):\n",
        "    S = librosa.feature.melspectrogram(y=audio, sr=fs)\n",
        "    S_db = librosa.power_to_db(S, ref=np.max)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "\n",
        "    img = librosa.display.specshow(S_db, sr=fs,\n",
        "                                 x_axis='time',\n",
        "                                 y_axis=y_axis,\n",
        "                                 cmap=cmap,\n",
        "                                 ax=ax)\n",
        "\n",
        "    fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
        "    ax.set_title(title)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    return fig, ax"
      ],
      "metadata": {
        "id": "fO3Rszhoo_jS"
      },
      "id": "fO3Rszhoo_jS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def actualizar(pitch=1.0, show_original=True):\n",
        "    f0_mod = _f0 * pitch\n",
        "    y_mod = pw.synthesize(f0_mod, sp, ap, fs)\n",
        "    display(Audio(y_mod, rate=fs))\n",
        "\n",
        "    # Graficar curvas de F0\n",
        "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
        "    ax1.plot(t, _f0, label='F0 original', color='blue') if show_original else None\n",
        "    ax1.plot(t, f0_mod, label=f'F0 x{pitch:.2f}', color='red', linestyle='--')\n",
        "    ax1.set_title(\"Curvas de F0\")\n",
        "    ax1.set_xlabel(\"Tiempo (s)\")\n",
        "    ax1.set_ylabel(\"Frecuencia (Hz)\")\n",
        "    ax1.grid()\n",
        "    ax1.legend()\n",
        "\n",
        "    # Graficar espectrograma modificado\n",
        "    S_mod = librosa.feature.melspectrogram(y=y_mod, sr=fs)\n",
        "    S_db_mod = librosa.power_to_db(S_mod, ref=np.max)\n",
        "    img_spec = librosa.display.specshow(S_db_mod, sr=fs, x_axis='time', y_axis='mel', ax=ax2, cmap='magma')\n",
        "    fig.colorbar(img_spec, ax=ax2, format=\"%+2.0f dB\")\n",
        "    ax2.set_title(f\"Espectrograma (Pitch x{pitch:.2f})\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "pitch_slider = widgets.FloatSlider(\n",
        "    value=1.0,\n",
        "    min=0.1,\n",
        "    max=2.0,\n",
        "    step=0.1,\n",
        "    description='Pitch:',\n",
        "    continuous_update=False\n",
        ")\n",
        "\n",
        "ui = widgets.VBox([\n",
        "    pitch_slider\n",
        "])\n",
        "\n",
        "out = widgets.interactive_output(\n",
        "    actualizar,\n",
        "    {'pitch': pitch_slider}\n",
        ")\n",
        "\n",
        "display(ui,out)"
      ],
      "metadata": {
        "id": "YJWAMMWNsuRD"
      },
      "id": "YJWAMMWNsuRD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "fe676b78",
      "metadata": {
        "id": "fe676b78"
      },
      "source": [
        "## SÍNTESIS NEURONAL"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f69317fe",
      "metadata": {
        "id": "f69317fe"
      },
      "source": [
        "Hemos presenciado estos últimos años un avance increíble sobre la IA y sus capacidades, conduciendo a una nueva era a los sistemas de texto a voz. Usando inteligencia artificial, se entrenan modelos que aprenden cómo suena el habla humana de verdad. Ya no se pegan sonidos ni se simulan con fórmulas; ahora se genera la voz desde cero, una muestra de audio a la vez.\n",
        "\n",
        "A continuación, hemos puesto a vuestra disposición un modelo basado en redes neuronales. En él podréis observar una diferencia tanto auditiva como en la generación de su espectrograma, así como la mejora con respecto a la síntesis paramétrica.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1KoKFLZtSPnsq8vcRAwfxMH7OuAwACoZI\" style=\"width:700px; height:200;\" />\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d08d93f2",
      "metadata": {
        "id": "d08d93f2"
      },
      "outputs": [],
      "source": [
        "def text_to_speech_with_spectrogram(text, lang='es', slow=False, filename='output.mp3', show_spectrogram=True):\n",
        "    tts = gTTS(text=text, lang=lang, slow=slow)\n",
        "\n",
        "    temp_file = \"gtts_temp.wav\"\n",
        "    tts.save(temp_file)\n",
        "\n",
        "    display(Audio(temp_file, autoplay=False))\n",
        "\n",
        "    if show_spectrogram:\n",
        "        data, sample_rate = sf.read(temp_file)\n",
        "\n",
        "        if len(data.shape) > 1:\n",
        "            data = np.mean(data, axis=1)\n",
        "\n",
        "        frequencies, times, spectrogram = signal.spectrogram(data, sample_rate, nperseg=512)\n",
        "        plt.pcolormesh(times, frequencies, 10 * np.log10(spectrogram), shading='gouraud')\n",
        "        plt.colorbar(label='Intensidad (dB)')\n",
        "        plt.ylabel('Frecuencia (Hz)')\n",
        "        plt.xlabel('Tiempo (s)')\n",
        "        plt.title('Espectrograma del audio generado')\n",
        "        plt.ylim(0, 8000)\n",
        "\n",
        "    os.remove(temp_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a02bfd1",
      "metadata": {
        "id": "8a02bfd1"
      },
      "outputs": [],
      "source": [
        "text_to_speech_with_spectrogram(\n",
        "    text=\"Muestra de audio\",\n",
        "    lang='es',\n",
        "    slow=False,\n",
        "    show_spectrogram=True\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}